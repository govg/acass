<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Govind Gopakumar</title>
        <link rel="stylesheet" href="../css/default.css" />
        <link rel="stylesheet" href="../css/syntax.css" />
		<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML.js"></script>
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../">/home</a>
            </div>
            <div id="navigation">
                <a href="../codes.html">Codes</a>
                <a href="../resources.html">Resources</a>
				<a href="../slides.html">Slides</a>
            </div>
        </div>

        <div id="content">
            <h1>Day 6 - Unsupervised Learning</h1>
            <div class="info">
    Posted on June  5, 2017
    
        by Govind Gopakumar
    
</div>

<h1 id="prelude">Prelude</h1>
<h2 id="announcements">Announcements</h2>
<ul>
<li>New project groups : Meet after class for short discussion</li>
<li>Programming tutorials to be put up tonight / tomorrow</li>
<li>Webpage - govg.github.io/acass</li>
</ul>
<h2 id="story-so-far">Story so far</h2>
<h3 id="supervised-learning">Supervised Learning</h3>
<ul>
<li>KNN, Distance from means</li>
<li>Decision Trees, Random Forests</li>
<li>Logistic Regression, Perceptron</li>
<li>Linear Regression</li>
</ul>
<h3 id="techniques">Techniques</h3>
<ul>
<li>Gradient Descent</li>
<li>Formulating a loss function</li>
<li>Using “maximum probability” to obtain results</li>
</ul>
<h1 id="clustering">Clustering</h1>
<h2 id="clustering---i">Clustering - I</h2>
<h3 id="why-do-we-need-it">Why do we need it?</h3>
<ul>
<li>Discover patterns or “clusters”</li>
<li>Preprocessing step for classification</li>
<li>Allow us to learn “generative” models</li>
</ul>
<h3 id="whats-the-easiest-way-to-do-it">What’s the easiest way to do it?</h3>
<ul>
<li>Group objects together</li>
<li>But how?</li>
</ul>
<h2 id="clustering---ii">Clustering - II</h2>
<h3 id="model-overview">Model overview</h3>
<ul>
<li>K-Means clustering : defined by k points</li>
<li>Each data point is assigned closest mean</li>
<li>K is sort of a hyper parameter, not to be learnt!</li>
</ul>
<h3 id="training-the-model">Training the model</h3>
<ul>
<li>How do we find the means?</li>
<li>How do we do assignment?</li>
<li>What are the parameters to be learnt?</li>
</ul>
<h2 id="clustering---iii">Clustering - III</h2>
<h3 id="model-parameters">Model parameters</h3>
<ul>
<li>Known : Location of data</li>
<li>Unknown : Cluster assignments, cluster means</li>
</ul>
<h3 id="how-to-find-both">How to find both?</h3>
<ul>
<li>Knowing cluster means let us find cluster assignments</li>
<li>Knowing cluster assignments : does it help the other way around?</li>
</ul>
<h2 id="clustering---iv">Clustering - IV</h2>
<h3 id="alternating-optimization">Alternating optimization</h3>
<ul>
<li>Two different unknown parameters : <span class="math inline">\(\mu, \z\)</span></li>
<li>Idea from matrix factorization.</li>
</ul>
<h3 id="finding-the-parameters">Finding the parameters</h3>
<ul>
<li>How do we do alternating optimization here?</li>
<li>What are the guesses?</li>
<li>What does it say about our “loss function”?</li>
</ul>
<h2 id="clustering---v">Clustering - V</h2>
<h3 id="geometry-of-the-model">Geometry of the model</h3>
<ul>
<li>Decision surface?</li>
<li>What sort of clusters does it learn?</li>
<li>When will it do badly?</li>
</ul>
<h3 id="uniqueness-of-clustering">Uniqueness of clustering</h3>
<ul>
<li>What does final cluster depend on?</li>
<li>Will it always learn good clustering?</li>
<li>What’s an example where it will fail?</li>
</ul>
<h1 id="conclusion">Conclusion</h1>
<h2 id="concluding-remarks">Concluding Remarks</h2>
<h3 id="takeaways">Takeaways</h3>
<h3 id="announcements-1">Announcements</h3>
<h2 id="references">References</h2>
<ul>
<li><a href="https://cse.iitk.ac.in/users/piyush/courses/ml_autumn16/771A_lec7_slides.pdf">Lecture 7, CS 771 IIT Kanpur</a></li>
<li><a href="https://cse.iitk.ac.in/users/piyush/courses/ml_autumn16/771A_lec6_slides.pdf">Lecture 6, CS 771 IIT Kanpur</a></li>
</ul>


        </div>

        <div id="footer">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </div>
    </body>
</html>
